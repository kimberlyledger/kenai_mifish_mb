---
title: "PCR replicate decontamination and biological replicate summary"
author: "Kimberly Ledger"
date: "2024-10-04"
output: html_document
---

bioinformatic decontamination of kenia mifish metabarcoding asvs and replicates

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

libraries
```{r}
library(tidyverse)
rename <- dplyr::rename
```

load sample metadata
```{r}
sample_metadata <- read.csv("/home/kimberly.ledger/kenai_mifish_mb/sample_names.csv")

#illumina output changed "_" to "-"
sample_metadata$sample_ID <- gsub("_", "-", sample_metadata$sample_ID) 
sample_metadata$sample_ID_date <- gsub("_", "-", sample_metadata$sample_ID_date) 
```

check sequence table outputs
```{r}
asv_table <- readRDS("/home/kimberly.ledger/kenai_mifish_mb/kenai_20231027/post/filtered.seqTab.RDS") %>%
  select(!Row.names)

#transpose 
asv_table <- data.frame(t(asv_table))

#set column names to be ASV# 
colnames(asv_table) <- asv_table["ASV",]

#remove row that has ASV#
asv_table <- asv_table[!rownames(asv_table) %in% c('ASV'), ]

#make sure reads are numbers
# Convert all character columns to numeric
for (col in names(asv_table)) {
  asv_table[[col]] <- as.numeric(asv_table[[col]])
}

#make make sample ID a column 
asv_table$sample_ID <- rownames(asv_table)
```


add column to the ASV table that labels the sample type
```{r}
# asv_table_with_sample_type <- sample_metadata %>%
#   dplyr::select(sample_ID_date, sample_type, collection_year, project, seq_date) %>%
#   left_join(asv_table, by = "sample_ID_date") %>%
#   unite(col = "project_year", project, collection_year, sep = "_", remove = F)

asv_table_with_sample_type <- asv_table %>%
  mutate(sample_type = ifelse(str_starts(sample_ID, "H2O"), "pcr_blank", NA),
         sample_type = ifelse(str_starts(sample_ID, "STURG"), "positive", sample_type),
         sample_type = ifelse(str_detect(sample_ID, "^\\d"), "sample", sample_type),)

# make a variable for the first and last ASV column in the table
asv_first <- which(colnames(asv_table_with_sample_type) == "ASV_0001")
asv_last <- max(which(str_detect(colnames(asv_table_with_sample_type), "^ASV_")))
```

# account for likely contaminants 

- tag-jumping
- consider reads in the negative PCR controls
- consider reads in the field negatives

## Step 1. Account for tag-jumping by using the positive controls 

subtract the proportion of reads that jumped into the positive control samples from each environmental sample 

plot positives first
```{r}
asv_table_with_sample_type %>%
  pivot_longer(cols = c(asv_first:asv_last), names_to = "ASV", values_to = "reads") %>%
  mutate(reads = ifelse(is.na(reads), 0, reads)) %>%
  filter(sample_type %in% c("positive")) %>%
  filter(reads > 0) %>%
  ggplot(aes(x=sample_ID, y=reads, fill=ASV)) +
  geom_bar(stat = "identity") + 
  theme_bw() +
  labs(
    y = "number of sequencing reads",
    x = "sample ID",
    title = "ASV reads - positive controls") + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.text = element_text(size = 8),
    legend.key.size = unit(0.3, "cm"),
    #legend.position = "none",
    legend.title = element_blank()
  )
```

since STURG1-C and STRUG2-C don't actually have sturgeon reads, i'll exclude those from the tag-jumping decontamination. but will need to figure out what happened there. 

identify the maximum proportion of reads for each ASV found in the positive controls
```{r}
prop_asvs_in_positives <- asv_table_with_sample_type %>%
  filter(sample_type == "positive") %>%
  filter(!sample_ID %in% c("STURG1-C", "STURG2-C")) %>%
  pivot_longer(cols = c(asv_first:asv_last), names_to = "ASV", values_to = "reads") %>%
  group_by(sample_ID) %>%
  mutate(TotalReadsPerSample = sum(reads)) %>%
  mutate(Prop = reads/TotalReadsPerSample) %>%
  group_by(ASV) %>%
  summarise(max_prop = max(Prop)) %>%
  arrange(desc(max_prop))
prop_asvs_in_positives
```

ASVs 12, 44, and 76 are sturgeon. good. 
very low levels of tag-jumping. 

subtract the max proportion of tag-jumped reads for each ASV from samples
```{r}
indexhop_table <- asv_table_with_sample_type %>%
  pivot_longer(cols = c(asv_first:asv_last), names_to = "ASV", values_to = "reads") %>%
  mutate(reads = ifelse(is.na(reads), 0, reads)) %>%
  group_by(sample_ID) %>%
  mutate(TotalReadsPerSample = sum(reads, na.rm = T)) %>%
  left_join(prop_asvs_in_positives, by = c("ASV")) %>%
  mutate(IndexHoppingReads = TotalReadsPerSample*max_prop) %>%
  mutate(reads_IndexHop_removed = reads - IndexHoppingReads) %>%
  mutate(reads_IndexHop_removed = if_else(reads_IndexHop_removed < 0, 0, reads_IndexHop_removed))
head(indexhop_table)
```

clean up the table by removing columns no longer needed 
```{r}
asv_table_filter1 <- indexhop_table %>%
  dplyr::select(sample_ID, sample_type, ASV, reads_IndexHop_removed) %>%
  dplyr::rename(reads = reads_IndexHop_removed)
```

this is a summary of the number of reads removed by ASV and sample_ID
```{r}
decontaminated_1 <- indexhop_table %>%
  dplyr::select(sample_ID, sample_type, ASV, IndexHoppingReads) %>%
  filter(sample_type == "sample") %>%
  group_by(ASV) %>%
  summarise(mean_reads = mean(IndexHoppingReads),
            reads_q.05 = quantile(IndexHoppingReads, probs=0.05),
            median_q.5 = median(IndexHoppingReads),
            reads_q.95 = quantile(IndexHoppingReads, probs=0.95)) %>%
  filter(mean_reads > 0)
decontaminated_1  
```

## Step 2. Remove ASVs only in controls and not in environmental samples and any ASVs that have more reads in controls than in environmental samples

number of reads
```{r}
reads_per_type_ASV <- asv_table_filter1 %>%
  group_by(ASV, sample_type) %>%
  summarize(TotalReadsPerASV = sum(reads, na.rm = TRUE)) %>%
  arrange(ASV)
```

what ASVs have no reads in samples, but reads in the controls? 
```{r}
not_in_samples <- reads_per_type_ASV %>%
  pivot_wider(names_from = "sample_type", values_from = c("TotalReadsPerASV")) %>%
    filter(sample < 1)
not_in_samples
```


what ASVs do have reads in samples, but more reads in the controls? 
```{r}
more_in_pcr_blanks <- reads_per_type_ASV %>%
  pivot_wider(names_from = "sample_type", values_from = c("TotalReadsPerASV")) %>%
  filter(sample > 1) %>%
  filter(pcr_blank > sample)
head(more_in_pcr_blanks)

# more_in_extraction_blanks <- reads_per_type_ASV %>%
#   pivot_wider(names_from = "sample_type", values_from = c("TotalReadsPerASV")) %>%
#   filter(sample > 1) %>%
#   filter(extraction_blank > sample)
# head(more_in_extraction_blanks)

more_in_pc_blanks <- reads_per_type_ASV %>%
  pivot_wider(names_from = "sample_type", values_from = c("TotalReadsPerASV")) %>%
  filter(sample > 1) %>%
  filter(positive > sample)
head(more_in_pc_blanks)

# more_in_fb_blanks <- reads_per_type_ASV %>%
#   pivot_wider(names_from = "sample_type", values_from = c("TotalReadsPerASV")) %>%
#   filter(sample > 1) %>%
#   filter(field_blank > sample)
# head(more_in_fb_blanks)
```

remove these from the asv table
```{r}
asv_table_filter2 <- asv_table_filter1 %>%
  filter(!ASV %in% not_in_samples$ASV) %>%
  filter(!ASV %in% more_in_pcr_blanks$ASV) %>%
  #filter(!ASV %in% more_in_extraction_blanks$ASV) %>%
  filter(!ASV %in% more_in_pc_blanks$ASV) #%>%
  #filter(!ASV %in% more_in_fb_blanks$ASV)
```


## Step 3. Remove ASVs without taxonomic ID 

now lets see how many of these ASVs have taxonomic IDs (these are not final tax ids)
```{r}
taxonomy <- read.csv("/home/kimberly.ledger/kenai_mifish_mb/outputs/taxonomy_collapsed.csv") %>%
  select(!X) %>%
  rename(ASV = qseqid)
```

```{r}
asv_table_filter2_with_tax <- asv_table_filter2 %>%
  left_join(taxonomy)
```

what ASV's do not have a taxonomic ID? 
```{r}
asv_table_filter2_with_tax %>%
  filter(is.na(taxon)) %>%
  group_by(ASV) %>%
  summarize(total_reads = sum(reads, na.rm = T))
```

remove ASVs with no taxonomic id
```{r}
asv_table_filter3 <- asv_table_filter2_with_tax %>%
  filter(!is.na(taxon))
```


## Step 4. Consider what is still in the negative controls - on a run-by-run basis

```{r}
asv_table_filter3 %>%
  filter(sample_type %in% c("pcr_blank")) %>%
  filter(reads > 0) %>%
  ggplot(aes(x=sample_ID, y=reads, fill=taxon)) +
  geom_bar(stat = "identity") + 
  theme_bw() +
  labs(
    y = "number of sequencing reads",
    x = "sample ID",
    title = "ASV reads - pcr blanks") + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.text = element_text(size = 8),
    legend.key.size = unit(0.3, "cm"),
    #legend.position = "none",
    legend.title = element_blank()
  )
```

keep this at the asv level
```{r}
asvs_PCRN <- asv_table_filter3 %>%
  filter(sample_type %in% c("pcr_blank")) %>%
  group_by(sample_type, ASV) %>%
  summarise(total = sum(reads),
            max = max(reads),
            mean = mean(reads)) %>%
  arrange(desc(total)) %>%
  filter(total > 0)

asvs_PCRN
```

let sonia decide how to handle this. for now, I will NOT subtract any reads from samples based on the PCR negative controls. 
```{r}
# asvs_PCRN_mean <- asvs_PCRN %>%
#   select(!total) %>%
#   select(!max)
#   
# pcrn_table <- asv_table_filter3 %>%
#   left_join(asvs_PCRN_mean, by = c("seq_date", "ASV")) %>%
#   mutate(mean = ifelse(is.na(mean), 0, mean)) %>%
#   mutate(reads_pcrn_removed = reads - mean) %>%
#   mutate(reads_pcrn_removed = if_else(reads_pcrn_removed < 0, 0, reads_pcrn_removed))
# pcrn_table
```

clean up the table by removing columns no longer needed 
```{r}
# asv_table_filter4 <- pcrn_table %>%
#   select(!reads) %>%
#   select(!mean) %>%
#   dplyr::rename(reads = reads_pcrn_removed)
```


## Step 5.  Address field negatives. 

CONTINUE HERE ONCE I HAVE METADATA>>> 

```{r}
asv_table_filter4 %>%
  filter(sample_type == "field_blank") %>%
  ggplot(aes(x=sample_ID, y=reads, fill=taxon)) +
  geom_bar(stat = "identity") + 
  theme_bw() +
  labs(
    y = "number of sequencing reads",
    x = "sample ID",
    title = "ASV reads - field blanks") + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.text = element_text(size = 8),
    legend.key.size = unit(0.3, "cm"),
    legend.position = "none",
    legend.title = element_blank()
  )
```


```{r}
#write.csv(asv_table_filter3, "/home/kimberly.ledger/kenai_mifish_mb/outputs/decontaminated_asv_table.csv")
```
